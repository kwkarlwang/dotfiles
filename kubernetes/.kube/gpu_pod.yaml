apiVersion: v1
kind: Pod
metadata:
  name: karl
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: gpu-type
            operator: In
            values:
            - "2080Ti"
            - "V100"
  containers:
  - name: gpu-container
    image: gitlab-registry.nautilus.optiputer.net/jiacheng/docker-images:torch17v4_jiacheng
    # image: gitlab-registry.nrp-nautilus.io/kwkarlwang/nautilus:latest
    #image: gitlab-registry.nrp-nautilus.io/kwkarlwang/nautilus/cache:42ca96050d9df4acb2b86c7d6d623208053da7edab9ecd0fad08cb4814990082

    args: ["sleep", "infinity"]
    volumeMounts:
    - mountPath: /data
      name: data
    - mountPath: /dev/shm
      name: dshm
    resources:
      limits:
        memory: 8Gi
        nvidia.com/gpu: "2"
        cpu: "2"
      requests:
        memory: 8Gi
        nvidia.com/gpu: "2"
        cpu: "2"
  restartPolicy: Never
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: storage
    - name: dshm
      emptyDir:
        medium: Memory
        
